<!-- 统计学的边界（5）：小结一下，and…… -->

## again，我们为什么需要解释概率呢？
> 定义女巫，并不说明女巫真的存在。

从数学角度讲，我们可以基于Kolmogrov公理定义一个自洽的概率函数。但这个数学定义并没有告诉我们概率到底是什么，所以当我们用这样的数学工具来理解现实世界的问题、物理领域和其他科学理论，我们并不明确这样的解释是否真的有意义。

换句话说，要是只有概率的数学定义，我们并不知道"量子粒子有 50% 的概率处于某个状态"到底意味着什么，也不知道"为什么不能说量子粒子有 80% 的概率是 A 同时有 60% 的概率是 B"。

## 直观理解几种概率解释
我们在前几篇文章里主要介绍了三大类概率解释：
* **认识论解释**，包括经典解释和逻辑/证据解释；
* **主观解释**，主要是主观贝叶斯解释；
* **客观解释**，包括频率解释、倾向性解释和最佳系统解释。

### 认识论解释
> 我们实际上是在学习证据和假设之间的关系。

在这些解释里，我们使用概率来理解"一个证据该怎么支持一个假设"。为了做到这一点，经典解释提出了**无差别原则**和**继承法则**。可问题是，Bertrand 悖论划定了这些概率理论的使用边界：任何在不同参数化下不自洽的问题都不能被这样思考。而且，无差别原则本身就是缺乏可证伪性的形而上学断言。

另一方面，逻辑解释是建立在逻辑语言和相应的赋值规则之上的。但是这样的逻辑语言只能够处理绝对性的**total evidence**，并且对于无限宇宙和有限证据时几乎毫无贡献。

证据解释干脆拒绝任何形式化表述，上来就假设存在一个证据概率函数 $P(h|e)$。可这办法回答不了"应该哪个 $P$ ？"

### 主观解释
> 概率是我们主观置信度的度量。

主观解释论从"荷兰赌"游戏入手，要求理性主体给事件分配一个前后一致的主观价值。问题是，不是每个人都想用同样的方式"赢钱"，而且理性主体的界定和选择本身也缺乏统一标准。进一步，主观概率把"专家意见"的影响纳入考量，来解释"理想的理性主体"的表现和行为。**Principal Principle** 是其中最重要的定律之一，它假设世界上有个客观的机会/置信函数，而这一来就把主观概率引向了客观概率……

### 客观解释
> 概率是世界的客观特征。

频率解释把概率定义为有限/无限宇宙里相对频率的极限。可它得面对**单次事件问题**和**参考序列问题**。

倾向性解释将概率抽象至更高层级，将其看成某物理系统产生特定结果的内在倾向。但不同的解释流派，最终都碰到了内在的矛盾……

最佳系统解释论进一步提升了抽象层级，把概率视为主宰宇宙演化的"最佳系统"的一部分。然而，这种观点依赖于主观判断或形而上学假设来决定什么是"最佳系统"。

## 或许它们是一回事……

#### Principal Principle：主观 VS 客观解释

前面的blog中讲过，***Principal Principle*** 是指：

> 一旦得知客观机会/倾向值函数，主观解释里的理想理性主体应当相应设定自己的置信度，

这直接连接了两种概率解释。另一方面，最佳系统解释理论中，仰赖于主观判断来决定什么是"最佳系统"，这又把它引向了主观解释。

#### Probabilistic Enkrasia：认识论 VS 主观解释

同时，我们用 ***Probabilistic Enkrasia*** 来描述另一个维度上的自我一致性：

> 我们的对于某件事件的置信度，应当与我们对于所有证据对其的支持程度保持一致。

这一原则和 Principal Principle 类似，将其他解释论中的概念引入主观解释中，进一步模糊了不同解释之间的界限。

#### 定律与原则：客观 VS 认识论解释

最后，我们注意到认识论解释依赖于诸如"无差别原则"、逻辑语言或证据概率函数在内的假设作为理论基石。那么，我们应该把它们看作某种"客观法则"吗？

## 总的来说，为什么我们理解概率时会碰到这么多麻烦？
> 概率，受制于其不确定的本质，可能只能立足于形而上学……🤔

从前面的讨论看，每次想给概率下个定义，最后都不得不回归于某些形而上学的假设。在认识论解释里，我们需要假设无差别原则、逻辑概率赋值规则或证据概率函数的成立。在主观解释里，客观机会函数，又绕回到客观解释论。至于客观解释，那些假设和定义都立足于不可证伪的玄学假设。

为什么我们不能像经典物理学和电磁学一样，将理论建构于若干可证伪的定律上呢？原因很简单：我们永远不能因为一枚硬币连续抛出 10,000 次正面就说它不公平。换句话说，仅有"硬币只出正面"或"硬币永远不出正面"这种极端假设才能被证伪。概率天然具备的不确定性，似乎注定了我们只能通过一些形而上学的假设来理解它。

## 回到最初的问题：LLM能写出《红楼梦》吗？
> Well, well, well……

### 人类是怎么写作的？
要思考这个问题，我们得先厘清人类如何写作。由于缺乏专业的理解和认识，我只提出几个直观简单的假设，这些假设不一定真实，只作为我们分析的若干抓手。

我相信**人类不仅仅是生物机器**，所以数学物理模型只能模拟或解释人类的外在表现，而无法"拟合"人类的自由意志。在这个意义上，单纯模仿人类行为只能得到不伦不类的结果：一方面，大语言模型试图通过模拟人类行为而成为真人；另一方面，基于统计学和大数据的学习方式注定了它们的学习与人类的学习方式完全不同。

我相信**人类是根据自己的记忆来写东西的**，包括一生中经历的、学到的、想过的一切，以及自身的对应状态。这也决定了一个人的记忆极其局限，不可能面面俱到。

我相信**人类尤其绝对的复杂性**，因此任何试图精确复制一个人行为的尝试都将失败。换句话说，极其详细地复制人类——复制每个细胞和分子、重现一模一样的环境和记忆——是不可能。反过来说，如果上述复制行为真的成功了，那我们或许就要承认我们与这样的造物没有本质的区别。当然，现在聊的大语言模型对人类行为的模仿远远没有达到这种程度。

### 大语言模型是怎么工作的？
我们把主流的大语言模型简化成一个抽象的数学函数

$$
f(\cdot;\theta),
$$

其中 $\theta$ 代表训练算法和模型结构。这个函数的输入包括

$$
\begin{cases}
\mathcal{D}_{train}, \text{ 训练数据},\\
T, \text{ 上下文},
\end{cases}
$$

而 $f$ 的输出是下一个词元的分布。函数 $f$ 的训练过程会最大化训练数据 $\mathcal{D}_{train}$ 的似然，因此这些训练数据决定了后续模型的推理行为。然后，给定特定的上下文 $T$，$f(\cdot|\mathcal{D}_{train}, T;\theta)$ 就是下一个词元的预测分布。

#### -> 直观来说……

举个直观的例子 ——

* `训练数据` $\mathcal{D}_{train}$ 包含大量人类撰写的文本，如小说、新闻和科学论文。

* 每次`函数` $f$ 收到一个`上下文` $T$（例如"你好，最近"），它就会输出下一个词元的概率分布。

    | 概率 | 候选词元 |
    | --- | --- |
    | 0.99 | "怎么样？" |
    | 0.005 | "吃了吗，" |
    | 0.001 | "小红" |
    | ... | ... |

    然后，根据上述分布采样下一个词元，所以我们几乎总是得到"你好，最近怎么样？"作为输出。反过来，我们也可以通过将句子中每个词元的概率相乘来计算该句子的预测概率。

* 大语言模型的`训练过程`就是通过调整函数 $f$，让训练数据中句子的平均预测概率尽可能大。通过这样的训练调整，要是有台写作机器跟 $f$ 一样工作，这机器就"很可能"会写出跟训练数据一样的句子。

### 在不同的概率解释下，怎么理解大语言模型？

#### 1. 认识论解释

按这种解释，大语言模型拟合底层机制，这种机制决定了

> ***怎么量化证据 $e$ 对假设 $h$ 的支持力度***，
 其中 $$\begin{cases}
h=\text{下一个可能词元}\\
e=\text{训练数据和上下文}
\end{cases}。$$

可是考虑到经典解释的界限，像"写出《红楼梦》"这种事件需要被详细限定，以避免任何不自洽的重新参数化可能性。这就要求我们将作者的人生经历全部作为上下文，并且剔除那堆过分全面的训练数据。对于现在的大语言模型来说，这种要求显然不现实。

至于逻辑解释，除了它自身存在的问题，思考"怎么写书"这样的问题还涉及大量"partial evidence"。这样的情况并不能被逻辑解释论所处理。

#### 2. 主观解释

从主观解释论出发，大语言模型应当把训练数据当成分配概率或确信度的"专家"（请看<a href="insights_and_ideas.html?id=2026-2-10-the-boundary-of-statistics-(3)-subjective-probability">这篇博客</a>）。这么一来，主观解释要求的理想"理性主体"就变成了训练数据代表的在统计意义上存在的"平均人"。

> ***大语言模型在模仿平均人。***

比如说，地球上要是有 33.3% 的人说"我最喜欢的光是红光"，33.3% 说"我最喜欢的光是绿光"，33.3% 说"我最喜欢的光是蓝光"，那么大语言模型可能以相等的概率输出它们，要么输出"我最喜欢的光是白光"（呃，因为"白色"是三种光混出来的😅）。这种范式的训练能让大语言模型学会一般性写作技巧（比如基本语法和常用语汇等），可问题是"我们不是平均人，我们是有个性的个体"。

#### 3. 客观解释

要是我们希望采用客观解释，那首先得把频率解释排除掉，因为"写出一本书"是一件不可重复的事件。采用另外两种客观解释论，我们可以将大语言模型的拟合目标理解为"下一个词元"的客观条件分布，这是由自然语言的底层机制或宇宙法则决定的。在本质上，这就像搭建一个模拟物理世界的物理引擎。

> ***大语言模型在模拟我们宇宙中客观的词元生成过程。***

然而，这种想法把我们人类当成了被某些客观定律和原则支配的可预测机器，从而否定了我们人类的自由意志。

## 结论

我们简单了解了几种解释概率的方式，主要包括认识论解释、主观解释和客观概率。这些不同的学派彼此紧密相连，且归根结底——由于概率固有的不确定性——都建立于某些形而上学的假设。

而在试图理解"大语言模型是否能写《红楼梦》"时，我们发现人类写作和大语言模型的工作原理之间存在几个核心差异：

* `LLM学得太多`，即大语言模型采用了基于统计学的学习路径，从巨量全面的数据集里学习写作技能。而作为上万年演化的结果，我们的人脑在固有的生物结构里就编码了基本能力。

* `LLM学得太少`，也就是大语言模型学不来一个完整的人一辈子的记忆，而这才是人类写作的底子。这些信息不光量大，而且涵盖多模态内容。

上面这些区别，归根结底是因为 <u>*大语言模型不像人类那样进化*</u>。我们的大脑是漫长进化过程的产物，不是统计&奖励驱动的训练过程的产物。我们生来就有精巧的大脑结构，通过自己的人生轨迹学说话、学写字。我们的视野和见解极其有限，而正是这样的局限性赋予了我们自由意志、个性、创造力，给予我们尊严。

要是能模拟整个宇宙的历史，或者哪怕只是一个人一辈子的所有经历，一个硅基的模型能写出《红楼梦》吗？谁知道呢……🐵

<h2 style="text-align: center;">人类的尊严！📖</h2>