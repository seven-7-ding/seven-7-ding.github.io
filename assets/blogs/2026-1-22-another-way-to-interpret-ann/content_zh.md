<!-- # 理解人工神经网络的另一种视角 -->

> 人工神经网络（ANN）是模仿生物大脑的工作方式。这里主要关注从微观角度模拟大脑的主流神经网络，例如全连接网络（FCN）、卷积神经网络（CNN）、循环神经网络（RNN）等。

## 神经网络的四个关键组成部分

直观地说，神经网络由一堆相互连接的神经元组成，可以被看作是一个**有向图**。每个神经元从其他神经元接收输入，处理后将输出发送给其他神经元。

根据我的理解，每个神经网络都有四个关键组成部分：
* 神经元状态更新的规则；
* 神经元之间的连接方式；
* 神经元感知输入和提供输出的方式；
* 神经元连接的更新方式。

## 这些组成部分的生物学版本是如何工作的？

虽然这些组成部分的生物学版本尚未完全被理解，但我们确实有一些基本认知，可以被用作与ANN机制相比较的基准。

**- 神经元状态更新的规则。**

在自然界的神经网络中，神经元状态变化涉及基因表达、离子通道动力学和突触传递等一系列电和化学复杂过程。从一般意义上讲，神经元整合传入信号，处理它们，并生成输出信号。<u>"阈值"机制或许是其中最重要的特性之一。</u>

**- 神经元之间的连接方式。**

神经元通过*突触*相互连接。作为一种自然结构，<u>大量突触能够并行传输信号</u>。

此外，<u>这个庞大的动态网络具有时间感知能力，这意味着不同信号到达的顺序和时间中能够蕴含信息。</u>

**- 神经元感知输入和提供输出的方式。**

生物具有不同的感觉器官来感知不同类型的输入，然后将其转换为<u>"标准"神经信号</u>。同时，某些神经元也提供这样的信号作为最终输出来控制效应器。

**- 神经元连接的更新方式。**

人们普遍认为，神经元连接的更新构成了学习的主要机制，因为这一过程使网络能够将过去的经验纳入其适应过程中。

在真实的神经网络中，<u>突触连接通过复杂的生化过程进行更新</u>。各种类型的细胞、器官和生物过程相互协作以实现这一目标。

## 人工神经网络如何实现这些组成部分？

数学上，我们将神经网络建模为一个有向图 $G=(V,E)$，其中 $V$ 是 $N$ 个神经元（节点）的集合，$E$ 是它们之间连接（边）的集合。

首先，我们将所有神经元在时间步 $t$ 的状态表示为向量 $h_t \in \mathbb{R}^N$。

在下一个时间步中，神经元通过激活函数 $\delta_t$ 决定它们的输出，产生激活向量

$$a_t = \delta_t(h_t).$$

然后，输出通过连接传输，并使用加权和进行整合。这个过程可以表示为

$$h_{t+1} = A_t a_t=A_t \delta_t(h_t),$$

其中 $A_t \in \mathbb{R}^{N \times N}$ 是图 $G$ 在时间步 $t$ 的加权邻接矩阵。这个过程将重复几个时间步，对应于全连接网络中的多层、卷积/循环神经网络中的信息传递，或循环神经网络中的时间步。

<a href="..\blogs\2026-1-22-another-way-to-interpret-ann/image_1.jpg" target="_blank">
    <img src="..\blogs\2026-1-22-another-way-to-interpret-ann/image_1.jpg" alt="ANN Interpretation" style="display: block; margin: 10px auto;" />
</a>

🌟最后，神经元的状态基于接收到的输入以及可能的先前状态进行更新。一个常见的更新规则是通过反向传播给出的：

$$A_{t}' = A_t - \eta \frac{\partial L}{\partial A_t},\forall A_t$$

其中 $L$ 是损失函数，$\eta$ 是学习率。

---

**简而言之，人工神经网络通过以下公式模拟生物神经网络：**

$$
\text{通过连接更新神经元状态：} h_{t+1} = A_t \delta_t(h_t)
$$

$$
\text{神经元连接更新：} A_{t}' = A_t - \eta \frac{\partial L}{\partial A_t}
$$

## 有哪些不同之处？

如前所述，人工神经网络以高度简化的方式模拟生物神经网络。正因如此，神经网络的几个关键特征并未被人工神经网络所捕获。

#### 过度简化的神经连接更新规则

人工神经网络通常使用<u>**基于梯度下降的方法**</u>来更新连接权重，提供了一种计算效率极高的，能够提取过去经验中有效信息并用于网络状态更新的数学机制。

但这种方法严重缩小了可能的更新规则范围。在生物神经网络中，突触连接的更新不仅受最终输出与所考虑突触之间关系的影响，还受控于神经元状态、相邻突触的"权重"等因素。这些因素形成了一种复杂的非线性关系，难以用确定性的数学公式来完全模拟。

#### 启发式"refreshing"机制

在目前的研究中，如何维持人工神经网络的可学习性（plasticity/learnability）被广泛认为是一个重要挑战。借鉴于生物神经网络，我们或许可以

- 定期清理<u>**$\approx 0$ 的权重**</u>（现有方法包括 <a href="https://arxiv.org/abs/2302.12902">ReDo</a>，它重置激活值接近零的神经元；以及 <a href="https://arxiv.org/abs/2505.24061">GraMa</a>，它重置梯度接近零的连接）；

- 基于特定规则创建新连接。

#### 信号的时间感知编码/解码

虽然像 RNN 和 Transformer 这样的人工神经网络已然能够处理时序输入，但现有ANN很少利用神经信号内可能存在的基于时间维度编码的信息。

在生物神经网络中，一方面，信号的时间和顺序承载了重要信息。如长时程增强（LTP）和短时程增强（STP）等已知机制表明，突触前和突触后神经电信号的到达时间可以影响其发送的神经冲动强度。<u>**这种机制有效地将网络维度的复杂性部分转移到了时间维度上。**</u>🕜

另一方面，神经网络的输入和输出信号也可以以时间感知的方式进行编码。值得一提的是，视觉 Transformer 中将*图片切分为序列*的想法在某种程度上与这个概念相似。📈

#### 大规模并行计算

在生物神经网络中，大量过程并行发生。这种并行性确保了高效的信息处理和复杂架构的可行性。

## 那么，新型网络可以是什么样的？

基于上述的理解，于是有了许多完全不负责任的（doge）想法：

* 使用包括遗传和强化学习在内的算法构建一个"连接更新模块"，该模块负责基于各种因素，以高度灵活的方式更新神经元间连接。

* 为神经信号的解释和传输设计时间感知方案。（<a href="https://zhuanlan.zhihu.com/p/416187474">脉冲神经网络（SNN）</a>可以被视为这方面的初步尝试。）

* 也许我们确实需要新颖的硬件架构来支持大规模并行计算……😇

<h2 style="text-align: center;">为自己是一个自然生物而深感自豪！🪼</h2>

---

1st version on 2026-01-22
